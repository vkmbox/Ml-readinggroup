{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27ba114",
   "metadata": {},
   "source": [
    "FFN output distribution for input gaussian-distributed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6fc248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947e907",
   "metadata": {},
   "source": [
    "***\n",
    "In the following example a FFN with Relu activation is studying. Input data is an array ${xx}$ of size ${n_0}$ x ${n_d}$, ${n_0}$ - input data dimension and ${n_d}$ - number of points in trainset. A series of ${experiments\\_number}$ experiments is performed, each one generating FFN weights from a distribution at criticality. Output data is an array ${yy}$ of size ${experiments\\_number}$ x ${n_l}$ x ${n_d}$, where ${n_l}$ - output data dimension.\n",
    "***\n",
    "TODO: check corellaion-coef between neurons, check criticality for \"K = 0 universality class\" e.g. tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ad4dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_covariance(neuron_one, trainpoint_one, neuron_two, trainpoint_two, yy):\n",
    "    '''Sample covariance, formulas as in https://en.wikipedia.org/wiki/Sample_mean_and_covariance'''\n",
    "    one = yy[:, neuron_one-1, trainpoint_one-1]\n",
    "    two = yy[:, neuron_two-1, trainpoint_two-1]\n",
    "    nn, mean_one, mean_two, sum = len(one), np.mean(one), np.mean(two), 0.0\n",
    "    for pos in range(nn):\n",
    "        sum += (one[pos]-mean_one)*(two[pos]-mean_two)\n",
    "\n",
    "    return sum/(nn - 1)\n",
    "\n",
    "def K_xx(trainpoint_one, trainpoint_two, cw, xx):\n",
    "    '''Metric (4.8) calculation'''\n",
    "    one, two = xx[:,trainpoint_one-1],xx[:,trainpoint_two-1]\n",
    "    nn, sum = len(one), 0.0\n",
    "    for pos in range(nn):\n",
    "        sum += one[pos]*two[pos]\n",
    "\n",
    "    return sum*cw/nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef7fa85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n0=3, nk=10, nl=3, l=3, bias_on=False):\n",
    "        '''n0: # dimension of x\n",
    "           nk: # hidden nodes\n",
    "           nl: # dimension of y\n",
    "           l: # number of layers\n",
    "           bias_on: # whether bias is included into linear preactivations'''\n",
    "        if l < 2:\n",
    "            raise Exception(\"FFN must have at least two layers\")\n",
    "        super().__init__()\n",
    "        self.n0=n0\n",
    "        self.nk=nk\n",
    "        self.nl=nl\n",
    "        self.bias_on = bias_on\n",
    "        self.log_level = None\n",
    "        self.hidden_linears = []\n",
    "        self.output_linear = None\n",
    "        print(\"FeedForwardNet created with n0={}, nk={}, nl={}, l={}, bias_on={}\".format(n0, nk, nl, l, bias_on))\n",
    "\n",
    "        self.hidden_linears.append(nn.Linear(n0, nk, bias=bias_on))\n",
    "        if l > 2:\n",
    "            for _ in range(2, l):\n",
    "                self.hidden_linears.append(nn.Linear(nk, nk, bias=bias_on))\n",
    "        self.output_linear = nn.Linear(nk, nl, bias=bias_on)\n",
    "\n",
    "    def set_log_level(self, value):\n",
    "        self.log_level = value\n",
    "\n",
    "    def get_log_level(self):\n",
    "        if self.log_level in (\"debug\", \"info\", \"warning\", \"error\"):\n",
    "            return self.log_level\n",
    "        else:\n",
    "            return \"info\"\n",
    "\n",
    "    def init_weights(self, cb=1.0, cw=1.0):\n",
    "        if self.get_log_level() == \"debug\":\n",
    "            print(\"FeedForwardNet weights initialised with cb={}, cw={}\".format(cb, cw))\n",
    "\n",
    "        #Weight initialisation as in 2.19, 2.20\n",
    "        n_prev = self.n0\n",
    "        for linear in self.hidden_linears:\n",
    "            init_linear_weights(linear, self.bias_on, math.sqrt(cb), math.sqrt(cw/n_prev))\n",
    "            n_prev = linear.weight.size()[0]\n",
    "\n",
    "        init_linear_weights(self.output_linear, self.bias_on, math.sqrt(cb), math.sqrt(cw/n_prev))\n",
    "\n",
    "\n",
    "def init_linear_weights(linear, bias_on, std_b=1.0, std_w=1.0):\n",
    "    nn.init.normal_(linear.weight, mean = 0., std = std_w)\n",
    "    n_prev = linear.weight.size()[0]\n",
    "    if bias_on:\n",
    "        nn.init.normal_(linear.bias, mean = 0., std = std_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877499d",
   "metadata": {},
   "source": [
    "FFN with PReLU(slope_positive, slope_negative); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3710c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParametricReLUNet(FeedForwardNet):\n",
    "    def __init__(self, n0=3, nk=10, nl=3, l=3, bias_on=False):\n",
    "        super().__init__(n0, nk, nl, l, bias_on)\n",
    "        self.slope_positive = None\n",
    "        self.slope_negative = None\n",
    "\n",
    "    def set_slopes(self, slope_positive = 1.0, slope_negative = 0.25):\n",
    "        self.slope_positive = slope_positive\n",
    "        self.slope_negative = slope_negative\n",
    "\n",
    "    def PReLU(self, input: Tensor) -> Tensor:\n",
    "        for pos in range(input.size(dim=0)):\n",
    "            input[pos] = input[pos] * (self.slope_positive if input[pos] >= 0 else self.slope_negative)\n",
    "        return input\n",
    "\n",
    "    def forward(self, xx):\n",
    "        if self.slope_positive == None:\n",
    "            raise Exception(\"To use forward set slopes with call ParametricReLUNet.set_slopes(...)\")\n",
    "\n",
    "        zk = torch.tensor(xx.transpose(), dtype=torch.float32)\n",
    "        for linear in self.hidden_linears:\n",
    "            zk = linear(zk)\n",
    "            zk = self.PReLU(zk)\n",
    "\n",
    "        zk = self.output_linear(zk)\n",
    "        return zk.detach().numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adc6609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNet created with n0=3, nk=10, nl=3, l=3, bias_on=False\n",
      "tensor([ 0.5500, -0.4400])\n"
     ]
    }
   ],
   "source": [
    "#Test for PReLU-activation implementation\n",
    "\n",
    "testPReLU = ParametricReLUNet()\n",
    "testPReLU.set_slopes(0.5, 0.2)\n",
    "resultPReLU = testPReLU.PReLU(torch.tensor(np.array([1.1,-2.2]), dtype=torch.float32))\n",
    "print(resultPReLU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b14d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNet created with n0=3, nk=10000, nl=2, l=10, bias_on=False\n"
     ]
    }
   ],
   "source": [
    "'''n0: # dimension of x\n",
    "    nk: # hidden nodes\n",
    "    nl: # dimension of y\n",
    "    l: # number of layers\n",
    "    nd: # number of points in train-set'''\n",
    "n0,nk,nl,l=3,10000,2,10\n",
    "nd = 2\n",
    "'''slope_plus, slope_minus: # slopes for Relu\n",
    "    experiments_number: # number of experiments'''\n",
    "slope_plus, slope_minus=1.0, 0.5\n",
    "experiments_number = 20\n",
    "\n",
    "testNet = ParametricReLUNet(n0=n0,nk=nk,nl=nl,l=l)\n",
    "testNet.set_log_level(\"info\")\n",
    "testNet.set_slopes(slope_plus, slope_minus)\n",
    "xx = np.random.normal(size=(n0, nd)).astype(np.float32)\n",
    "yy = np.zeros((experiments_number, nl, nd))\n",
    "cw= 2.0/(slope_plus**2.0 + slope_minus**2.0)\n",
    "\n",
    "#for each experiment re-initialisation of the weights with recalculation\n",
    "for experiment_number in range(experiments_number):\n",
    "    #weights distribution is initialisied as in (5.67)\n",
    "    testNet.init_weights(0, cw)\n",
    "    for col in range(nd):\n",
    "        res = testNet.forward(xx[:,col])\n",
    "        for row in range(nl):\n",
    "            yy[experiment_number,row,col] = res[row]\n",
    "\n",
    "#print(\"xx:\", xx)\n",
    "#print(\"yy:\", yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68c0c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample covariance between neuron 1, trainpoint 1 and neuron 1, trainpoint 1: 2.536925866829671\n",
      "Sample covariance between neuron 1, trainpoint 1 and neuron 1, trainpoint 2: 0.421680354338156\n",
      "Sample covariance between neuron 1, trainpoint 2 and neuron 1, trainpoint 2: 0.6874493674450934\n",
      "Sample covariance between neuron 1, trainpoint 1 and neuron 2, trainpoint 1: 0.0246808046153056\n",
      "Sample covariance between neuron 1, trainpoint 1 and neuron 2, trainpoint 2: -0.4496034114315628\n",
      "Sample covariance between neuron 1, trainpoint 2 and neuron 2, trainpoint 1: -0.2977825183867778\n",
      "Sample covariance between neuron 1, trainpoint 2 and neuron 2, trainpoint 2: -0.28839502120915705\n",
      "Sample covariance between neuron 2, trainpoint 1 and neuron 2, trainpoint 1: 3.1855002493832614\n",
      "Sample covariance between neuron 2, trainpoint 1 and neuron 2, trainpoint 2: 0.41108618828226706\n",
      "Sample covariance between neuron 2, trainpoint 2 and neuron 2, trainpoint 2: 0.7705387239097569\n"
     ]
    }
   ],
   "source": [
    "#nll = 2 #Subset 1..nll of output neurons for analysis\n",
    "for neuron1 in range(1, nl+1):\n",
    "      for neuron2 in range(neuron1, nl+1):\n",
    "            for trainpoint1 in range(1, nd+1):\n",
    "                  for trainpoint2 in range(1 if neuron1 != neuron2 else trainpoint1, nd+1):\n",
    "                        print(\"Sample covariance between neuron {}, trainpoint {} and neuron {}, trainpoint {}: {}\"\\\n",
    "                              .format(neuron1, trainpoint1, neuron2, trainpoint2\\\n",
    "                                      , sample_covariance(neuron1,trainpoint1,neuron2,trainpoint2,yy)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f1f3877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric (4.8) for trainpoint 1 and trainpoint 1: 2.46060097416242\n",
      "Metric (4.8) for trainpoint 1 and trainpoint 2: -0.7259547154108684\n",
      "Metric (4.8) for trainpoint 2 and trainpoint 2: 0.8724368969599406\n"
     ]
    }
   ],
   "source": [
    "for trainpoint1 in range(1, nd+1):\n",
    "    for trainpoint2 in range(trainpoint1, nd+1):\n",
    "        print(\"Metric (4.8) for trainpoint {} and trainpoint {}: {}\"\\\n",
    "              .format(trainpoint1, trainpoint2, K_xx(trainpoint1, trainpoint2, cw, xx)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
