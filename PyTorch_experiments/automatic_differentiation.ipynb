{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a634c7c0",
   "metadata": {},
   "source": [
    "### Inconsistencies that I found when calculating derivatives by manual calculation and automatic differentiation methods, please help to find the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16fa1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18bb6e",
   "metadata": {},
   "source": [
    "***\n",
    "In the example a NN with one hidden layer and sigmoid activation is considered. The NN has a matrix ${U}$ m x d of parameters for the hidden layer and a vector $\\vec{W}$ 1 x m of parameters for the output layer.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a46ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerNet(nn.Module):\n",
    "    def __init__(self, m=10, d=3):\n",
    "        '''m: # hidden nodes\n",
    "           d: # dimensions of x'''\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.linear1 = nn.Linear(d, m, bias=False)\n",
    "        nn.init.normal_(self.linear1.weight)  # initialize with std gaussian\n",
    "        self.linear2 = nn.Linear(m, 1, bias=False)\n",
    "        nn.init.normal_(self.linear2.weight)\n",
    "        #self.linear2.weight.requires_grad_(False)\n",
    "        # self.linear2.weight.bernoulli_()\n",
    "        # self.linear2.weight *= 2\n",
    "        # self.linear2.weight -= 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        #print(\"net-1: \", x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #print(\"net-2: \", x)\n",
    "        output = self.linear2(x).squeeze()/np.sqrt(self.m)  # scale by 1/sqrt(m)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e733c9",
   "metadata": {},
   "source": [
    "***\n",
    "NN and an array of input data are initialised below.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b5ba68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN initialisation\n",
    "width = 10\n",
    "testNet = SingleLayerNet(width)\n",
    "weights1 = testNet.linear1.weight.detach().numpy()\n",
    "weights2 = testNet.linear2.weight.detach().numpy()\n",
    "\n",
    "#Input data\n",
    "inp = np.random.normal(size=(3, 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239f618",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{The derivation formulas for the network with respect to the coefficients $\\vec{W},{U}$ are as follows:}}$<br>\n",
    "***\n",
    "&emsp;This NN is equivalent to the following expression:\n",
    "$$f(\\vec{W},{U}) = \\frac{1}{\\sqrt{m}} \\sum \\limits _{k=1} ^{m} \\frac{w_k}{(1+exp(-\\sum \\limits _{s=1} ^{d} u_{k,s} \\cdot x_s))}$$\n",
    "&emsp;Derivative with respect to the coefficient $w_k$:\n",
    "$$\\frac{\\partial f}{\\partial w_k} = \\frac{1}{\\sqrt{m}} \\frac{1}{(1+exp(-\\sum \\limits _{s=1} ^{d} u_{k,s} \\cdot x_s))}$$\n",
    "&emsp;Derivative with respect to the coefficient $u_{k,N}$:\n",
    "$$\\frac{\\partial f}{\\partial u_{k,N}} = \\frac{1}{\\sqrt{m}} \\frac{x_N \\cdot w_k \\cdot exp(-\\sum \\limits _{s=1} ^{d} u_{k,s} \\cdot x_s)}{(1+exp(-\\sum \\limits _{s=1} ^{d} u_{k,s} \\cdot x_s))^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63c64c",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Calculating derivatives using symbolic formulas:}}$<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abf094fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = np.matmul(weights1, inp).squeeze()\n",
    "tmp = np.exp(-1*tmp0)\n",
    "dw_calc = (1/np.sqrt(10))/(1+tmp)\n",
    "\n",
    "tmp2=(1+tmp)*(1+tmp)\n",
    "dtmp2=weights2*(1/np.sqrt(10))*tmp/tmp2 #\n",
    "du_calc = np.transpose(np.matmul(inp, dtmp2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec477e8",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Calculating derivatives using automatic differentiation:}}$<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "407377e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.tensor(inp.transpose(), dtype=torch.float32)\n",
    "out = testNet.forward(xx)\n",
    "df = torch.autograd.grad(out, (testNet.linear1.weight, testNet.linear2.weight)\\\n",
    "    , retain_graph=True, create_graph=True, allow_unused=True)\n",
    "du_ad = df[0].detach().numpy()\n",
    "dw_ad = df[1].detach().numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242ede5",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Comparison of the results of manual calculation and automatic differentiation:}}$<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "718c4e7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of derivatives with respect to coefficients U by automatic differentiation:\n",
      " [[-0.06903538 -0.03336043  0.01319817]\n",
      " [ 0.0153444   0.00741498 -0.00293354]\n",
      " [ 0.04801453  0.02320239 -0.00917941]\n",
      " [ 0.00712414  0.00344265 -0.00136199]\n",
      " [-0.06112475 -0.02953772  0.01168582]\n",
      " [ 0.03676222  0.01776486 -0.0070282 ]\n",
      " [-0.08028518 -0.03879675  0.01534891]\n",
      " [-0.00929642 -0.00449237  0.00177729]\n",
      " [ 0.03989149  0.01927703 -0.00762645]\n",
      " [-0.05342617 -0.02581749  0.01021401]]\n",
      "Matrix of derivatives with respect to coefficients U by manual calculation:\n",
      " [[-0.06903539 -0.03336044  0.01319818]\n",
      " [ 0.0153444   0.00741498 -0.00293354]\n",
      " [ 0.04801453  0.02320239 -0.00917941]\n",
      " [ 0.00712414  0.00344265 -0.00136199]\n",
      " [-0.06112474 -0.02953772  0.01168582]\n",
      " [ 0.03676222  0.01776486 -0.0070282 ]\n",
      " [-0.08028519 -0.03879676  0.01534891]\n",
      " [-0.00929642 -0.00449237  0.00177729]\n",
      " [ 0.03989148  0.01927703 -0.00762645]\n",
      " [-0.05342617 -0.02581749  0.01021401]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix of derivatives with respect to coefficients U by automatic differentiation:\\n\", du_ad)\n",
    "print(\"Matrix of derivatives with respect to coefficients U by manual calculation:\\n\", du_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "112ef7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of derivatives with respect to coefficients W by automatic differentiation:\n",
      " [0.24249876 0.2841476  0.08382694 0.00687479 0.06238763 0.20009805\n",
      " 0.14201619 0.00755101 0.141299   0.15766416]\n",
      "Matrix of derivatives with respect to coefficients W by manual calculation:\n",
      " [0.24249874 0.2841476  0.08382694 0.00687479 0.06238762 0.20009805\n",
      " 0.14201619 0.00755101 0.14129898 0.15766415]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix of derivatives with respect to coefficients W by automatic differentiation:\\n\", dw_ad)\n",
    "print(\"Matrix of derivatives with respect to coefficients W by manual calculation:\\n\", dw_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2276590",
   "metadata": {},
   "source": [
    "The derivatives on W coefficients are the same, but on U coefficients they are not. I think I got the symbolic expressions for derivatives right, maybe the error is in \"ğ‚ğšğ¥ğœğ®ğ¥ğšğ­ğ¢ğ§ğ  ğğğ«ğ¢ğ¯ğšğ­ğ¢ğ¯ğğ¬ ğ®ğ¬ğ¢ğ§ğ  ğ¬ğ²ğ¦ğ›ğ¨ğ¥ğ¢ğœ ğŸğ¨ğ«ğ¦ğ®ğ¥ğšğ¬\", although I have checked several times. Either I am using torch.autograd.grad incorrectly. Anyway, any help would be appreciated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2a077e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4505806e-09,  3.7252903e-09, -1.8626451e-09],\n",
       "       [-2.7939677e-09, -9.3132257e-10,  6.9849193e-10],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-7.4505806e-09, -1.8626451e-09,  9.3132257e-10],\n",
       "       [ 3.7252903e-09,  3.7252903e-09, -9.3132257e-10],\n",
       "       [ 7.4505806e-09,  3.7252903e-09, -1.8626451e-09],\n",
       "       [-9.3132257e-10, -4.6566129e-10,  1.1641532e-10],\n",
       "       [ 3.7252903e-09,  3.7252903e-09, -9.3132257e-10],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "du_ad - du_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153633e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
